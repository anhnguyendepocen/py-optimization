{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Optimizing-Matrix-Operations\" data-toc-modified-id=\"Optimizing-Matrix-Operations-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Optimizing Matrix Operations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Numpy-with-NumExpr\" data-toc-modified-id=\"Numpy-with-NumExpr-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Numpy with NumExpr</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Evaluation</a></span></li><li><span><a href=\"#Accelerating-loops\" data-toc-modified-id=\"Accelerating-loops-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Accelerating loops</a></span></li><li><span><a href=\"#Selecting-number-of-threads\" data-toc-modified-id=\"Selecting-number-of-threads-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Selecting number of threads</a></span></li><li><span><a href=\"#Supported-functions\" data-toc-modified-id=\"Supported-functions-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Supported functions</a></span></li><li><span><a href=\"#Supported-reduction-operations\" data-toc-modified-id=\"Supported-reduction-operations-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>Supported reduction operations</a></span></li></ul></li><li><span><a href=\"#Basic-operations-with-PyTorch\" data-toc-modified-id=\"Basic-operations-with-PyTorch-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Basic operations with PyTorch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Operations\" data-toc-modified-id=\"Operations-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Operations</a></span><ul class=\"toc-item\"><li><span><a href=\"#In-place-operation\" data-toc-modified-id=\"In-place-operation-1.2.1.1\"><span class=\"toc-item-num\">1.2.1.1&nbsp;&nbsp;</span>In-place operation</a></span></li><li><span><a href=\"#out\" data-toc-modified-id=\"out-1.2.1.2\"><span class=\"toc-item-num\">1.2.1.2&nbsp;&nbsp;</span>out</a></span></li><li><span><a href=\"#Indexing\" data-toc-modified-id=\"Indexing-1.2.1.3\"><span class=\"toc-item-num\">1.2.1.3&nbsp;&nbsp;</span>Indexing</a></span></li><li><span><a href=\"#Conversion-between-NumPy-ndarray-and-Tensor\" data-toc-modified-id=\"Conversion-between-NumPy-ndarray-and-Tensor-1.2.1.4\"><span class=\"toc-item-num\">1.2.1.4&nbsp;&nbsp;</span>Conversion between NumPy ndarray and Tensor</a></span></li><li><span><a href=\"#Tensor-meta-data\" data-toc-modified-id=\"Tensor-meta-data-1.2.1.5\"><span class=\"toc-item-num\">1.2.1.5&nbsp;&nbsp;</span>Tensor meta-data</a></span></li><li><span><a href=\"#Reshape-Tensor\" data-toc-modified-id=\"Reshape-Tensor-1.2.1.6\"><span class=\"toc-item-num\">1.2.1.6&nbsp;&nbsp;</span>Reshape Tensor</a></span></li></ul></li><li><span><a href=\"#Create-Tensors\" data-toc-modified-id=\"Create-Tensors-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Create Tensors</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-and-Initializing-Tensors\" data-toc-modified-id=\"Creating-and-Initializing-Tensors-1.2.2.1\"><span class=\"toc-item-num\">1.2.2.1&nbsp;&nbsp;</span>Creating and Initializing Tensors</a></span></li><li><span><a href=\"#Creating-random-Tensors\" data-toc-modified-id=\"Creating-random-Tensors-1.2.2.2\"><span class=\"toc-item-num\">1.2.2.2&nbsp;&nbsp;</span>Creating random Tensors</a></span></li><li><span><a href=\"#Tensor-Types\" data-toc-modified-id=\"Tensor-Types-1.2.2.3\"><span class=\"toc-item-num\">1.2.2.3&nbsp;&nbsp;</span>Tensor Types</a></span></li><li><span><a href=\"#Identity-matrices-and-Filled-matrices\" data-toc-modified-id=\"Identity-matrices-and-Filled-matrices-1.2.2.4\"><span class=\"toc-item-num\">1.2.2.4&nbsp;&nbsp;</span>Identity matrices and Filled matrices</a></span></li><li><span><a href=\"#Range-filled-Tensor\" data-toc-modified-id=\"Range-filled-Tensor-1.2.2.5\"><span class=\"toc-item-num\">1.2.2.5&nbsp;&nbsp;</span>Range-filled Tensor</a></span></li><li><span><a href=\"#Log-scale-and-linear-scale-tensors\" data-toc-modified-id=\"Log-scale-and-linear-scale-tensors-1.2.2.6\"><span class=\"toc-item-num\">1.2.2.6&nbsp;&nbsp;</span>Log-scale and linear scale tensors</a></span></li><li><span><a href=\"#ByteTensor\" data-toc-modified-id=\"ByteTensor-1.2.2.7\"><span class=\"toc-item-num\">1.2.2.7&nbsp;&nbsp;</span>ByteTensor</a></span></li></ul></li><li><span><a href=\"#Indexing,-Slicing,-Joining,-Mutating\" data-toc-modified-id=\"Indexing,-Slicing,-Joining,-Mutating-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Indexing, Slicing, Joining, Mutating</a></span><ul class=\"toc-item\"><li><span><a href=\"#Concatenate,-Stack\" data-toc-modified-id=\"Concatenate,-Stack-1.2.3.1\"><span class=\"toc-item-num\">1.2.3.1&nbsp;&nbsp;</span>Concatenate, Stack</a></span></li><li><span><a href=\"#Gather-(reorganize)-elements\" data-toc-modified-id=\"Gather-(reorganize)-elements-1.2.3.2\"><span class=\"toc-item-num\">1.2.3.2&nbsp;&nbsp;</span>Gather (reorganize) elements</a></span></li><li><span><a href=\"#Split-a-Tensor\" data-toc-modified-id=\"Split-a-Tensor-1.2.3.3\"><span class=\"toc-item-num\">1.2.3.3&nbsp;&nbsp;</span>Split a Tensor</a></span></li><li><span><a href=\"#Index-select-&amp;-Mask-select\" data-toc-modified-id=\"Index-select-&amp;-Mask-select-1.2.3.4\"><span class=\"toc-item-num\">1.2.3.4&nbsp;&nbsp;</span>Index select &amp; Mask select</a></span></li><li><span><a href=\"#Squeeze-&amp;-Unsqueeze\" data-toc-modified-id=\"Squeeze-&amp;-Unsqueeze-1.2.3.5\"><span class=\"toc-item-num\">1.2.3.5&nbsp;&nbsp;</span>Squeeze &amp; Unsqueeze</a></span></li><li><span><a href=\"#Non-zero-elements\" data-toc-modified-id=\"Non-zero-elements-1.2.3.6\"><span class=\"toc-item-num\">1.2.3.6&nbsp;&nbsp;</span>Non-zero elements</a></span></li><li><span><a href=\"#take\" data-toc-modified-id=\"take-1.2.3.7\"><span class=\"toc-item-num\">1.2.3.7&nbsp;&nbsp;</span>take</a></span></li><li><span><a href=\"#transpose\" data-toc-modified-id=\"transpose-1.2.3.8\"><span class=\"toc-item-num\">1.2.3.8&nbsp;&nbsp;</span>transpose</a></span></li></ul></li></ul></li><li><span><a href=\"#Math-with-PyTorch\" data-toc-modified-id=\"Math-with-PyTorch-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Math with PyTorch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distributions\" data-toc-modified-id=\"Distributions-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Distributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Uniform,-bernoulli,-multinomial,-normal\" data-toc-modified-id=\"Uniform,-bernoulli,-multinomial,-normal-1.3.1.1\"><span class=\"toc-item-num\">1.3.1.1&nbsp;&nbsp;</span>Uniform, bernoulli, multinomial, normal</a></span></li><li><span><a href=\"#Other-Distribution-operations\" data-toc-modified-id=\"Other-Distribution-operations-1.3.1.2\"><span class=\"toc-item-num\">1.3.1.2&nbsp;&nbsp;</span>Other Distribution operations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-Sampling\" data-toc-modified-id=\"Random-Sampling-1.3.1.2.1\"><span class=\"toc-item-num\">1.3.1.2.1&nbsp;&nbsp;</span>Random Sampling</a></span></li><li><span><a href=\"#In-place-random-sampling\" data-toc-modified-id=\"In-place-random-sampling-1.3.1.2.2\"><span class=\"toc-item-num\">1.3.1.2.2&nbsp;&nbsp;</span>In-place random sampling</a></span></li></ul></li></ul></li><li><span><a href=\"#Element-wise-operations\" data-toc-modified-id=\"Element-wise-operations-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Element-wise operations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Add,-subtract,-multiply,-etc..\" data-toc-modified-id=\"Add,-subtract,-multiply,-etc..-1.3.2.1\"><span class=\"toc-item-num\">1.3.2.1&nbsp;&nbsp;</span>Add, subtract, multiply, etc..</a></span></li><li><span><a href=\"#Transcendental-functions-and-other-point-wise-ops\" data-toc-modified-id=\"Transcendental-functions-and-other-point-wise-ops-1.3.2.2\"><span class=\"toc-item-num\">1.3.2.2&nbsp;&nbsp;</span>Transcendental functions and other point-wise ops</a></span></li></ul></li><li><span><a href=\"#Reduction-operations\" data-toc-modified-id=\"Reduction-operations-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Reduction operations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cumulative-sum,-mean,-product,-etc..\" data-toc-modified-id=\"Cumulative-sum,-mean,-product,-etc..-1.3.3.1\"><span class=\"toc-item-num\">1.3.3.1&nbsp;&nbsp;</span>Cumulative sum, mean, product, etc..</a></span></li><li><span><a href=\"#Other-reduction-operations\" data-toc-modified-id=\"Other-reduction-operations-1.3.3.2\"><span class=\"toc-item-num\">1.3.3.2&nbsp;&nbsp;</span>Other reduction operations</a></span></li></ul></li><li><span><a href=\"#Comparison-operations\" data-toc-modified-id=\"Comparison-operations-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Comparison operations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Equality-and-range\" data-toc-modified-id=\"Equality-and-range-1.3.4.1\"><span class=\"toc-item-num\">1.3.4.1&nbsp;&nbsp;</span>Equality and range</a></span></li><li><span><a href=\"#Sort\" data-toc-modified-id=\"Sort-1.3.4.2\"><span class=\"toc-item-num\">1.3.4.2&nbsp;&nbsp;</span>Sort</a></span></li><li><span><a href=\"#k-th-and-top-k\" data-toc-modified-id=\"k-th-and-top-k-1.3.4.3\"><span class=\"toc-item-num\">1.3.4.3&nbsp;&nbsp;</span>k-th and top k</a></span></li><li><span><a href=\"#Other-comparison-ops\" data-toc-modified-id=\"Other-comparison-ops-1.3.4.4\"><span class=\"toc-item-num\">1.3.4.4&nbsp;&nbsp;</span>Other comparison ops</a></span></li></ul></li><li><span><a href=\"#Matrix,-vector-multiplication\" data-toc-modified-id=\"Matrix,-vector-multiplication-1.3.5\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;</span>Matrix, vector multiplication</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dot-product-of-Tensors\" data-toc-modified-id=\"Dot-product-of-Tensors-1.3.5.1\"><span class=\"toc-item-num\">1.3.5.1&nbsp;&nbsp;</span>Dot product of Tensors</a></span></li><li><span><a href=\"#Matrix-vector-products\" data-toc-modified-id=\"Matrix-vector-products-1.3.5.2\"><span class=\"toc-item-num\">1.3.5.2&nbsp;&nbsp;</span>Matrix-vector products</a></span></li><li><span><a href=\"#Matrix-Matrix-products\" data-toc-modified-id=\"Matrix-Matrix-products-1.3.5.3\"><span class=\"toc-item-num\">1.3.5.3&nbsp;&nbsp;</span>Matrix-Matrix products</a></span></li><li><span><a href=\"#Batch-matrix-multiplication\" data-toc-modified-id=\"Batch-matrix-multiplication-1.3.5.4\"><span class=\"toc-item-num\">1.3.5.4&nbsp;&nbsp;</span>Batch matrix multiplication</a></span></li></ul></li><li><span><a href=\"#Other\" data-toc-modified-id=\"Other-1.3.6\"><span class=\"toc-item-num\">1.3.6&nbsp;&nbsp;</span>Other</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cross-product\" data-toc-modified-id=\"Cross-product-1.3.6.1\"><span class=\"toc-item-num\">1.3.6.1&nbsp;&nbsp;</span>Cross product</a></span></li><li><span><a href=\"#Diagonal-matrices\" data-toc-modified-id=\"Diagonal-matrices-1.3.6.2\"><span class=\"toc-item-num\">1.3.6.2&nbsp;&nbsp;</span>Diagonal matrices</a></span></li><li><span><a href=\"#Histogram\" data-toc-modified-id=\"Histogram-1.3.6.3\"><span class=\"toc-item-num\">1.3.6.3&nbsp;&nbsp;</span>Histogram</a></span></li><li><span><a href=\"#Renormalization\" data-toc-modified-id=\"Renormalization-1.3.6.4\"><span class=\"toc-item-num\">1.3.6.4&nbsp;&nbsp;</span>Renormalization</a></span></li><li><span><a href=\"#Additional-Linear-Algebra-operations\" data-toc-modified-id=\"Additional-Linear-Algebra-operations-1.3.6.5\"><span class=\"toc-item-num\">1.3.6.5&nbsp;&nbsp;</span>Additional Linear Algebra operations</a></span></li></ul></li><li><span><a href=\"#Additional-Operations\" data-toc-modified-id=\"Additional-Operations-1.3.7\"><span class=\"toc-item-num\">1.3.7&nbsp;&nbsp;</span>Additional Operations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tensors\" data-toc-modified-id=\"Tensors-1.3.7.1\"><span class=\"toc-item-num\">1.3.7.1&nbsp;&nbsp;</span>Tensors</a></span></li><li><span><a href=\"#Serialization\" data-toc-modified-id=\"Serialization-1.3.7.2\"><span class=\"toc-item-num\">1.3.7.2&nbsp;&nbsp;</span>Serialization</a></span></li><li><span><a href=\"#Parallelism\" data-toc-modified-id=\"Parallelism-1.3.7.3\"><span class=\"toc-item-num\">1.3.7.3&nbsp;&nbsp;</span>Parallelism</a></span></li><li><span><a href=\"#Spectral-Ops\" data-toc-modified-id=\"Spectral-Ops-1.3.7.4\"><span class=\"toc-item-num\">1.3.7.4&nbsp;&nbsp;</span>Spectral Ops</a></span></li><li><span><a href=\"#BLAS-and-LAPACK-operations\" data-toc-modified-id=\"BLAS-and-LAPACK-operations-1.3.7.5\"><span class=\"toc-item-num\">1.3.7.5&nbsp;&nbsp;</span>BLAS and LAPACK operations</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Matrix Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy with NumExpr\n",
    "\n",
    "The `numexpr` package provides routines for vas *evaluation* of elementwise evaluation of array expressions. It uses a vector-based virtual machine to do so.\n",
    "\n",
    "__Note that in order to see significant speedup from `numexpr`, arrays need to be around at least 128,000 or so elements.__ With less than this many elements, Numpy may be faster by default.\n",
    "\n",
    "It is very simple to use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T19:44:00.815473Z",
     "start_time": "2019-04-10T19:44:00.810488Z"
    }
   },
   "outputs": [],
   "source": [
    "help(ne.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T19:35:38.317071Z",
     "start_time": "2019-04-10T19:35:38.312084Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T19:47:44.572637Z",
     "start_time": "2019-04-10T19:47:44.565621Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.arange(1000000)\n",
    "b = np.arange(0, 2000000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T19:54:00.899520Z",
     "start_time": "2019-04-10T19:53:11.502687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.06 ms ± 88.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 (2*a+5*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T19:54:19.464312Z",
     "start_time": "2019-04-10T19:54:05.721085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.96 ms ± 58.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 ne.evaluate(\"2*a+5*b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerating loops\n",
    "\n",
    "`re_evaluate(local_dict=None)`: Re-evaluate the last array expression without any check. This is meant for accelerating loops that are re-evaluating the same expression repeatedly without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T22:30:12.147988Z",
     "start_time": "2019-04-10T22:30:12.140025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function re_evaluate in module numexpr.necompiler:\n",
      "\n",
      "re_evaluate(local_dict=None)\n",
      "    Re-evaluate the previous executed array expression without any check.\n",
      "    \n",
      "    This is meant for accelerating loops that are re-evaluating the same\n",
      "    expression repeatedly without changing anything else than the operands.\n",
      "    If unsure, use evaluate() which is safer.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    local_dict : dictionary, optional\n",
      "        A dictionary that replaces the local operands in current frame.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ne.re_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T20:08:42.998984Z",
     "start_time": "2019-04-10T20:08:42.994994Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_func1():\n",
    "    2*a+5*b\n",
    "    for i in range(10):\n",
    "        2*a+5*b\n",
    "\n",
    "def my_func2():\n",
    "    ne.evaluate(\"2*a+5*b\")\n",
    "    for i in range(10):\n",
    "        ne.re_evaluate()\n",
    "        \n",
    "def my_func3():\n",
    "    ne.evaluate(\"2*a+5*b\")\n",
    "    for i in range(10):\n",
    "        ne.evaluate(\"2*a+5*b\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T20:06:46.522263Z",
     "start_time": "2019-04-10T20:05:52.436932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.3 ms ± 1.39 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 my_func1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T20:07:01.547057Z",
     "start_time": "2019-04-10T20:06:46.523254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.5 ms ± 205 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 my_func2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T20:09:26.336233Z",
     "start_time": "2019-04-10T20:09:11.745272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.8 ms ± 616 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 my_func3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting number of threads\n",
    "\n",
    "By default NumExpr automatically detects the number of available logical processing cores and uses as many as it can, up to an initial count of 8. The default maximum that it is able to use is 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T19:53:09.661110Z",
     "start_time": "2019-04-10T19:52:05.655Z"
    }
   },
   "outputs": [],
   "source": [
    "help(ne.set_num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T19:54:25.023642Z",
     "start_time": "2019-04-10T19:54:25.016702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne.detect_number_of_cores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported functions\n",
    "\n",
    " - `where(bool, number1, number2): number` – number1 if the bool condition is true, number2 otherwise.\n",
    " - `{sin,cos,tan}(float|complex): float|complex` – trigonometric sine, cosine or tangent.\n",
    " - `{arcsin,arccos,arctan}(float|complex): float|complex` – trigonometric inverse sine, cosine or tangent.\n",
    " - `arctan2(float1, float2): float` – trigonometric inverse tangent of float1/float2.\n",
    " - `{sinh,cosh,tanh}(float|complex): float|complex` – hyperbolic sine, cosine or tangent.\n",
    " - `{arcsinh,arccosh,arctanh}(float|complex): float|complex` – hyperbolic inverse sine, cosine or tangent.\n",
    " - `{log,log10,log1p}(float|complex): float|complex` – natural, base-10 and log(1+x) logarithms.\n",
    " - `{exp,expm1}(float|complex): float|complex` – exponential and exponential minus one.\n",
    " - `sqrt(float|complex): float|complex` – square root.\n",
    " - `abs(float|complex): float|complex` – absolute value.\n",
    " - `conj(complex): complex` – conjugate value.\n",
    " - `{real,imag}(complex): float` – real or imaginary part of complex.\n",
    " - `complex(float, float): complex` – complex from real and imaginary parts.\n",
    " - `contains(str, str): bool` – returns True for every string in `op1` that contains `op2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported reduction operations\n",
    "\n",
    " - `sum(number, axis=None)`: Sum of array elements over a given axis. Negative axis are not supported.\n",
    " - `prod(number, axis=None)`: Product of array elements over a given axis. Negative axis are not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T23:05:01.668846Z",
     "start_time": "2019-04-10T23:04:56.933424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.16.1\n",
      "Time for an algebraic expression:     1.114 s / 1.003 GB/s\n",
      "Time for a transcendental expression: 1.745 s / 0.641 GB/s\n",
      "\n",
      "\n",
      "\n",
      "Numexpr version: 2.6.8. Using MKL: False\n",
      "Time for an algebraic expression:     0.186 s / 5.998 GB/s\n",
      "Time for a transcendental expression: 0.146 s / 7.680 GB/s\n",
      "\n",
      "\n",
      "\n",
      "Numexpr version: 2.6.8. Using MKL: True\n",
      "Time for an algebraic expression:     0.130 s / 8.581 GB/s\n",
      "Time for a transcendental expression: 0.165 s / 6.754 GB/s\n",
      "\n",
      "\n",
      "\n",
      "Numexpr version: 2.6.8. Using MKL: True\n",
      "AGGRESSIVE OPTIMIZATION ON and VML ACCURACY = 'fast'\n",
      "Time for an algebraic expression:     0.131 s / 8.537 GB/s\n",
      "Time for a transcendental expression: 0.140 s / 7.975 GB/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fast'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adapted from: \n",
    "# https://github.com/pydata/numexpr/blob/master/bench/vml_timing2.py\n",
    "\n",
    "# References:\n",
    "#\n",
    "# http://software.intel.com/en-us/intel-mkl\n",
    "# https://github.com/pydata/numexpr/wiki/NumexprMKL\n",
    "\n",
    "from __future__ import print_function\n",
    "import datetime\n",
    "import sys\n",
    "import numpy as np\n",
    "import numexpr as ne\n",
    "from time import time\n",
    "\n",
    "N = int(5e7)\n",
    "\n",
    "x = np.linspace(0, 1, N)\n",
    "y = np.linspace(0, 1, N)\n",
    "z = np.empty(N, dtype=np.float64)\n",
    "\n",
    "# Our working set is 3 vectors of N doubles each\n",
    "working_set_GB = 3 * N * 8 / 2**30\n",
    "\n",
    "print(\"NumPy version: %s\" % (np.__version__,))\n",
    "\n",
    "t0 = time()\n",
    "z = 2*y + 4*x\n",
    "t1 = time()\n",
    "gbs = working_set_GB / (t1-t0)\n",
    "print(\"Time for an algebraic expression:     %.3f s / %.3f GB/s\" % (t1-t0, gbs))\n",
    "\n",
    "t0 = time()\n",
    "z = np.sin(x)**2 + np.cos(y)**2\n",
    "t1 = time()\n",
    "gbs = working_set_GB / (t1-t0)\n",
    "print(\"Time for a transcendental expression: %.3f s / %.3f GB/s\" % (t1-t0, gbs))\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "ne.use_vml = False\n",
    "\n",
    "print(\"Numexpr version: %s. Using MKL: %s\" % (ne.__version__, ne.use_vml))\n",
    "\n",
    "t0 = time()\n",
    "ne.evaluate('2*y + 4*x', out = z)\n",
    "t1 = time()\n",
    "gbs = working_set_GB / (t1-t0)\n",
    "print(\"Time for an algebraic expression:     %.3f s / %.3f GB/s\" % (t1-t0, gbs))\n",
    "\n",
    "t0 = time()\n",
    "ne.evaluate('sin(x)**2 + cos(y)**2', out = z)\n",
    "t1 = time()\n",
    "gbs = working_set_GB / (t1-t0)\n",
    "print(\"Time for a transcendental expression: %.3f s / %.3f GB/s\" % (t1-t0, gbs))\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "ne.use_vml = True\n",
    "\n",
    "print(\"Numexpr version: %s. Using MKL: %s\" % (ne.__version__, ne.use_vml))\n",
    "\n",
    "t0 = time()\n",
    "ne.evaluate('2*y + 4*x', out = z)\n",
    "t1 = time()\n",
    "gbs = working_set_GB / (t1-t0)\n",
    "print(\"Time for an algebraic expression:     %.3f s / %.3f GB/s\" % (t1-t0, gbs))\n",
    "\n",
    "t0 = time()\n",
    "ne.evaluate('sin(x)**2 + cos(y)**2', out = z)\n",
    "t1 = time()\n",
    "gbs = working_set_GB / (t1-t0)\n",
    "print(\"Time for a transcendental expression: %.3f s / %.3f GB/s\" % (t1-t0, gbs))\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "ne.use_vml = True\n",
    "ne.set_vml_accuracy_mode('fast')\n",
    "\n",
    "print(\"Numexpr version: %s. Using MKL: %s\" % (ne.__version__, ne.use_vml))\n",
    "print(\"AGGRESSIVE OPTIMIZATION ON and VML ACCURACY = 'fast'\")\n",
    "\n",
    "t0 = time()\n",
    "ne.evaluate('2*y + 4*x', out = z)#, optimization='aggressive')\n",
    "t1 = time()\n",
    "gbs = working_set_GB / (t1-t0)\n",
    "print(\"Time for an algebraic expression:     %.3f s / %.3f GB/s\" % (t1-t0, gbs))\n",
    "\n",
    "t0 = time()\n",
    "ne.evaluate('sin(x)**2 + cos(y)**2', out = z)#, optimization='aggressive')\n",
    "t1 = time()\n",
    "gbs = working_set_GB / (t1-t0)\n",
    "print(\"Time for a transcendental expression: %.3f s / %.3f GB/s\" % (t1-t0, gbs))\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "ne.set_vml_accuracy_mode(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operations with PyTorch\n",
    "\n",
    "For the most part, PyTorch is a drop-in replacement for NumPy. Many familiar NumPy functions share the same name in PyTorch, so the API should be very familiar.\n",
    "\n",
    "The caveat is that PyTorch functions only operate on Tensor-objects, so any non-tensor objects and variables (including NumPy arrays) must be converted to PyTorch tensor objects.\n",
    "\n",
    "NumPy arrays can be converted to/from Tensor objects very easily, and even share the same memory space as the NumPy objects that they are converted to/from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:34:30.906440Z",
     "start_time": "2019-04-11T19:34:30.699995Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:38:05.106779Z",
     "start_time": "2019-04-11T19:38:05.100826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an un-initialized 2x3 Tensor object, filled with garbage data\n",
    "x = torch.Tensor(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:38:52.986128Z",
     "start_time": "2019-04-11T19:38:52.981109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1147, 0.3661, 0.9842],\n",
       "        [0.1387, 0.4167, 0.3372]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a 2x3 Tensor obj initialized with random values between 0 and 1\n",
    "y = torch.rand(2, 3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:40:45.221654Z",
     "start_time": "2019-04-11T19:40:45.216669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1147, 0.3661, 0.9842],\n",
      "        [0.1387, 0.4167, 0.3372]]) tensor([[0.1147, 0.3661, 0.9842],\n",
      "        [0.1387, 0.4167, 0.3372]])\n"
     ]
    }
   ],
   "source": [
    "# equivalent addition operations\n",
    "z1 = x+y\n",
    "z2 = torch.add(x, y)\n",
    "\n",
    "print(z1, z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:40:52.261601Z",
     "start_time": "2019-04-11T19:40:52.256653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take note of what boolean comparison of Tensors returns!\n",
    "z1==z2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "\n",
    "Fundamental syntax: `torch.is_tensor(obj)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-place operation\n",
    "\n",
    "All operations that end with `_` (an underscore) are in-place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:43:08.726191Z",
     "start_time": "2019-04-11T19:43:08.718212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1147, 0.3661, 0.9842],\n",
       "        [0.1387, 0.4167, 0.3372]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as x = x + y\n",
    "x.add_(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:43:58.647151Z",
     "start_time": "2019-04-11T19:43:58.642157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == z1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### out\n",
    "\n",
    "The result of an operation can be assigned to a variable, therefore all operation methods have an *out* parameter for storing the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:46:34.439653Z",
     "start_time": "2019-04-11T19:46:34.434668Z"
    }
   },
   "outputs": [],
   "source": [
    "r1 = torch.Tensor(2, 3)\n",
    "torch.add(x, y, out=r1)\n",
    "\n",
    "r2 = torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:46:34.789751Z",
     "start_time": "2019-04-11T19:46:34.784802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 == r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing\n",
    "\n",
    "Exactly the same as Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:49:07.981193Z",
     "start_time": "2019-04-11T19:49:07.975232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]] [0 3]\n"
     ]
    }
   ],
   "source": [
    "# numpy indexing\n",
    "import numpy as np\n",
    "a = np.asarray(range(6)).reshape(2,3)\n",
    "print(a, a[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:49:31.635389Z",
     "start_time": "2019-04-11T19:49:31.631434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 7.4906e-01  3.1742e-01  7.3682e-01\n",
      " 4.4933e-01  1.8515e+28  2.6686e+36\n",
      "[torch.FloatTensor of size 2x3]\n",
      " \n",
      " 0.7491\n",
      " 0.4493\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numpy-like indexing in Pytorch\n",
    "print(x, x[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:50:49.782025Z",
     "start_time": "2019-04-11T19:50:49.776010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00  3.1742e-01  7.3682e-01\n",
       " 0.0000e+00  1.8515e+28  2.6686e+36\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assignment with indexing\n",
    "x[:, 0] = 0\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:48:45.590925Z",
     "start_time": "2019-04-11T19:48:45.583905Z"
    }
   },
   "source": [
    "#### Conversion between NumPy ndarray and Tensor\n",
    "\n",
    "During conversion, both the ndarray and the Tensor will share the same memory. So, changing the NumPy array will also change the Tensor, and visa versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:54:07.000991Z",
     "start_time": "2019-04-11T19:54:06.995042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert\n",
    "a = np.array([1,2,3,4,5,6])\n",
    "v = torch.from_numpy(a)     # numpy to tensor\n",
    "\n",
    "b = v.numpy()    # tensor to numpy\n",
    "\n",
    "b[1] = -1   # change the tensor\n",
    "\n",
    "a[1] == b[1]   # show that they are both changed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:55:21.545563Z",
     "start_time": "2019-04-11T19:55:21.539581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()   # the size and dimension of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:55:22.316942Z",
     "start_time": "2019-04-11T19:55:22.311956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.numel(x)  # number of elements in x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape Tensor\n",
    "\n",
    "In PyTorch, the shape of a Tensor is called the \"view\":`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T19:57:47.040953Z",
     "start_time": "2019-04-12T19:57:41.688244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.5537 -1.3666 -0.6080\n",
      "-1.1840 -0.8511 -1.7338\n",
      "[torch.FloatTensor of size 2x3]\n",
      " \n",
      " 1.5537\n",
      "-1.3666\n",
      "-0.6080\n",
      "-1.1840\n",
      "-0.8511\n",
      "-1.7338\n",
      "[torch.FloatTensor of size 6]\n",
      " \n",
      " 1.5537 -1.3666\n",
      "-0.6080 -1.1840\n",
      "-0.8511 -1.7338\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Re-sizing a tensor\n",
    "x = torch.randn(2, 3) # size 2x3\n",
    "y = x.view(6)         # resize to 1x6\n",
    "z = x.view(-1, 2)     # resize to 3x2, note: does NOT exchange rows and cols\n",
    "\n",
    "print(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating and Initializing Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.Tensor(2,3) # A 2x3, un-initialized torch.FloatTensor filled with garbage data\n",
    "v = torch.Tensor([[1,2],[4,5]]) # 2x2 tensor initalized with specific values\n",
    "v = torch.LongTensor([1,2,3]) # a Tensor of Long-type data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T20:02:45.306850Z",
     "start_time": "2019-04-12T20:02:45.254737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1afd26f8810>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reproducible results with user-defined random seed\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T20:05:13.396999Z",
     "start_time": "2019-04-12T20:05:13.384601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.5159  0.1541  0.8908\n",
      " 0.3750  0.4596  0.0693\n",
      "[torch.FloatTensor of size 2x3]\n",
      " \n",
      " 0.3742  1.4532  1.4057\n",
      "-1.2860 -0.6946  0.1770\n",
      "[torch.FloatTensor of size 2x3]\n",
      " \n",
      " 2\n",
      " 1\n",
      " 3\n",
      " 0\n",
      "[torch.LongTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "v0 = torch.rand(2, 3)  # uniform distribution\n",
    "v1 = torch.randn(2, 3) # normal distribution (SD=1, mean=0)\n",
    "v2 = torch.randperm(4) # random permutation of integers from 0 to 4\n",
    "\n",
    "print(v0,v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T20:07:19.401279Z",
     "start_time": "2019-04-12T20:07:19.388736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.2330  0.6424  0.0899\n",
      " 1.4849  0.0087 -0.4798\n",
      " 0.9808  0.2786  1.6559\n",
      " 0.3677  2.5169  0.1226\n",
      "-0.3431 -0.8052 -0.8996\n",
      "[torch.FloatTensor of size 5x3]\n",
      " \n",
      "-0.1665 -1.2544  0.4524\n",
      "-1.8438 -0.6672  1.3412\n",
      "-0.6061 -1.3228  0.5589\n",
      "-0.0543  0.5147  0.3752\n",
      " 0.4385 -0.9105 -0.8118\n",
      "[torch.DoubleTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "v0 = torch.randn(5, 3).type(torch.FloatTensor)\n",
    "v1 = torch.randn(5, 3).type(torch.DoubleTensor)\n",
    "print(v0, v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identity matrices and Filled matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T20:14:36.303940Z",
     "start_time": "2019-04-12T20:14:36.292753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  0  0\n",
      " 0  1  0\n",
      " 0  0  1\n",
      "[torch.FloatTensor of size 3x3]\n",
      " \n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 10]\n",
      " \n",
      "(0 ,0 ,.,.) = \n",
      "  1\n",
      "  1\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "  1\n",
      "  1\n",
      "[torch.FloatTensor of size 2x1x2x1]\n",
      " \n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.FloatTensor of size 3x3]\n",
      " \n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 10]\n",
      " \n",
      " 1  1  1\n",
      " 2  2  2\n",
      " 3  3  3\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "I = torch.eye(3)  # 3x3 identity matrix\n",
    "\n",
    "v0 = torch.ones(10)\n",
    "v1 = torch.ones(2,1,2,1)\n",
    "v2 = torch.ones_like(I)\n",
    "\n",
    "v3 = torch.zeros(10)\n",
    "\n",
    "v4 = torch.ones(3, 3)\n",
    "v4[1].fill_(2)\n",
    "v4[2].fill_(3)\n",
    "\n",
    "print(I, v0, v1, v2, v3, v4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Range-filled Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T20:16:45.953514Z",
     "start_time": "2019-04-12T20:16:45.941368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[torch.FloatTensor of size 5]\n",
      " \n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[torch.FloatTensor of size 5]\n",
      " \n",
      " 0  1  2\n",
      " 3  4  5\n",
      " 6  7  8\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# similar to range, same API as np.arange\n",
    "v0 = torch.arange(5)\n",
    "v1 = torch.arange(0, 5, step=1)\n",
    "\n",
    "v2 = torch.arange(9).view(3,3)\n",
    "\n",
    "print(v0,v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log-scale and linear scale tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T20:18:44.870950Z",
     "start_time": "2019-04-12T20:18:44.862563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      " 10\n",
      "[torch.FloatTensor of size 10]\n",
      " \n",
      " 1.0000e-10\n",
      " 1.0000e-05\n",
      " 1.0000e+00\n",
      " 1.0000e+05\n",
      " 1.0000e+10\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "v0 = torch.linspace(1,10, steps=10)\n",
    "v1 = torch.logspace(start=-10, end=10, steps=5)\n",
    "\n",
    "print(v0, v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T20:19:18.868191Z",
     "start_time": "2019-04-12T20:19:18.856412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       "[torch.ByteTensor of size 4]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.ByteTensor([0,1,1,0])\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing, Slicing, Joining, Mutating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:10:21.763095Z",
     "start_time": "2019-04-11T20:10:21.757113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1  2\n",
       " 3  4  5\n",
       " 6  7  8\n",
       "[torch.FloatTensor of size 3x3]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare a Matrix for use in this section\n",
    "\n",
    "v = torch.arange(9).view(3,3)\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate, Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:10:43.970044Z",
     "start_time": "2019-04-11T20:10:43.964062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1     2\n",
       "    3     4     5\n",
       "    6     7     8\n",
       "    0     1     2\n",
       "    3     4     5\n",
       "    6     7     8\n",
       "    0     1     2\n",
       "    3     4     5\n",
       "    6     7     8\n",
       "[torch.FloatTensor of size 9x3]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((v,v,v), 0) #concat in the 0th dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:11:06.694731Z",
     "start_time": "2019-04-11T20:11:06.688748Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1     2     0     1     2     0     1     2\n",
       "    3     4     5     3     4     5     3     4     5\n",
       "    6     7     8     6     7     8     6     7     8\n",
       "[torch.FloatTensor of size 3x9]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((v,v,v), 1) #concat in the 1st dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather (reorganize) elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:16:54.288580Z",
     "start_time": "2019-04-11T20:16:54.282588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  2\n",
       " 3  4\n",
       " 7  8\n",
       "[torch.FloatTensor of size 3x2]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syntax:\n",
    "# torch.gather(input, dim, index, out=None)\n",
    "\n",
    "r = torch.gather(v, 1, torch.LongTensor([[0,2],[0,1],[1,2]]))\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:18:26.694287Z",
     "start_time": "2019-04-11T20:18:26.688303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  0  1  2\n",
       " [torch.FloatTensor of size 1x3], \n",
       "  3  4  5\n",
       " [torch.FloatTensor of size 1x3], \n",
       "  6  7  8\n",
       " [torch.FloatTensor of size 1x3])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into 3 chunks\n",
    "torch.chunk(v, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:18:34.635345Z",
     "start_time": "2019-04-11T20:18:34.629360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  0  1  2\n",
       "  3  4  5\n",
       " [torch.FloatTensor of size 2x3], \n",
       "  6  7  8\n",
       " [torch.FloatTensor of size 1x3])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into chunks of size 2 (or less)\n",
    "torch.split(v, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index select & Mask select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:31:51.866168Z",
     "start_time": "2019-04-11T20:31:51.861165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  1  2\n",
      " 3  4  5\n",
      " 6  7  8\n",
      "[torch.FloatTensor of size 3x3]\n",
      " \n",
      " 0  2\n",
      " 3  5\n",
      " 6  8\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# index-based select\n",
    "indices = torch.LongTensor([0,2])\n",
    "r = torch.index_select(v, 1, indices)\n",
    "print(v, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:34:18.920554Z",
     "start_time": "2019-04-11T20:34:18.914532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  0  0\n",
      " 0  1  1\n",
      " 1  1  1\n",
      "[torch.ByteTensor of size 3x3]\n",
      " \n",
      " 0  1  2\n",
      " 3  4  5\n",
      " 6  7  8\n",
      "[torch.FloatTensor of size 3x3]\n",
      " \n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 8\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mask select\n",
    "mask = v.ge(4) # create a mask, slecting all elements >= 4\n",
    "r = torch.masked_select(v, mask)\n",
    "print(mask, v, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Squeeze & Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T20:53:11.636029Z",
     "start_time": "2019-04-12T20:53:11.625843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,0 ,.,.) = \n",
      "  1\n",
      "  1\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "  1\n",
      "  1\n",
      "[torch.FloatTensor of size 2x1x2x1]\n",
      " \n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      " \n",
      "(0 ,.,.) = \n",
      "  1\n",
      "  1\n",
      "\n",
      "(1 ,.,.) = \n",
      "  1\n",
      "  1\n",
      "[torch.FloatTensor of size 2x2x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#squeeze\n",
    "t = torch.ones(2,1,2,1)\n",
    "r0 = torch.squeeze(t) #squeeze into a 2x2\n",
    "r1 = torch.squeeze(t, 1) # squeeze dimension one\n",
    "\n",
    "print(t, r0, r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T20:55:03.135465Z",
     "start_time": "2019-04-12T20:55:03.126270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      " \n",
      " 1  2  3\n",
      "[torch.FloatTensor of size 1x3]\n",
      " \n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#un-squeeze\n",
    "x = torch.Tensor([1,2,3])\n",
    "r0 = torch.unsqueeze(x, 0)\n",
    "r1 = torch.unsqueeze(x, 1)\n",
    "\n",
    "print(x, r0, r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-zero elements\n",
    "\n",
    "Selection index for all on-zero elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T20:57:25.933385Z",
     "start_time": "2019-04-12T20:57:25.922712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     0\n",
       "    1     1\n",
       "    2     0\n",
       "    2     1\n",
       "    3     0\n",
       "    5     0\n",
       "    5     1\n",
       "[torch.LongTensor of size 7x2]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.LongTensor([[1, 0],\n",
    "                      [0, 2],\n",
    "                      [2, 3],\n",
    "                      [2, 0],\n",
    "                      [0, 0],\n",
    "                      [1, 2]])\n",
    "\n",
    "r = torch.nonzero(v) # returns the [i, j] indices for all non-zero elements\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T21:02:08.320912Z",
     "start_time": "2019-04-12T21:02:08.313651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 3\n",
      " 9\n",
      " 1\n",
      "[torch.LongTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Flatten a Tensor and return elements with the given indices\n",
    "v = torch.LongTensor([[1, 0, 3],\n",
    "                      [7, 9, 1]])\n",
    "\n",
    "r = torch.take(v, torch.LongTensor([0, 2, 4, -1]))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T21:03:23.169473Z",
     "start_time": "2019-04-12T21:03:23.159605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  7\n",
       " 0  9\n",
       " 3  1\n",
       "[torch.LongTensor of size 3x2]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose dimensions 0 and 1\n",
    "torch.transpose(v, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform, bernoulli, multinomial, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T21:50:53.112853Z",
     "start_time": "2019-04-12T21:50:53.091295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.8860  0.3710\n",
      " 0.1769  0.8206\n",
      "[torch.FloatTensor of size 2x2]\n",
      " \n",
      " 1  1\n",
      " 0  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      " \n",
      " 3\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 4]\n",
      " \n",
      " 1.5864\n",
      " 2.0861\n",
      " 4.1725\n",
      " 3.4981\n",
      " 4.6949\n",
      " 6.6555\n",
      " 6.2695\n",
      " 8.0898\n",
      " 8.7139\n",
      " 9.9370\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2x2 uniformly distributed random matrix, range [0, 1]\n",
    "r0 = torch.Tensor(2, 2).uniform_(0,1)\n",
    "\n",
    "# bernoulli\n",
    "r1 = torch.bernoulli(r0)\n",
    "\n",
    "# multinomial\n",
    "w = torch.Tensor([0,4,8,2]) # Create a tensor of weights\n",
    "r2 = torch.multinomial(w, 4, replacement=True) # size 4\n",
    "\n",
    "# normal distribution\n",
    "# size 10\n",
    "r3 = torch.normal(means=torch.arange(1,11), std=torch.arange(1, 0.1, -0.1))\n",
    "\n",
    "print(r0,r1,r2,r3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Distribution operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Sampling\n",
    "```\n",
    ".. autofunction:: manual_seed    - Set a manual seed\n",
    ".. autofunction:: initial_seed   - Randomize a seed by the system\n",
    ".. autofunction:: get_rng_state\n",
    ".. autofunction:: set_rng_state\n",
    ".. autodata:: default_generator\n",
    ".. autofunction:: bernoulli\n",
    ".. autofunction:: multinomial\n",
    ".. autofunction:: normal\n",
    ".. autofunction:: rand\n",
    ".. autofunction:: randn\n",
    ".. autofunction:: randperm\n",
    "```\n",
    "\n",
    "##### In-place random sampling\n",
    "```\n",
    "- torch.Tensor.bernoulli_ - in-place version of :func:`torch.bernoulli`\n",
    "- torch.Tensor.cauchy_ - numbers drawn from the Cauchy distribution\n",
    "- torch.Tensor.exponential_ - numbers drawn from the exponential distribution\n",
    "- torch.Tensor.geometric_ - elements drawn from the geometric distribution\n",
    "- torch.Tensor.log_normal_ - samples from the log-normal distribution\n",
    "- torch.Tensor.normal_ - in-place version of :func:`torch.normal`\n",
    "- torch.Tensor.random_ - numbers sampled from the discrete uniform distribution\n",
    "- torch.Tensor.uniform_ - numbers sampled from the continuous uniform distribution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add, subtract, multiply, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T21:59:32.041833Z",
     "start_time": "2019-04-12T21:59:32.028562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      " \n",
      "  9\n",
      "  8\n",
      " 13\n",
      "[torch.FloatTensor of size 3]\n",
      " \n",
      " 69\n",
      " 38\n",
      "-47\n",
      "[torch.FloatTensor of size 3]\n",
      " \n",
      " 0.4495  0.2544\n",
      " 0.5000  0.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      " \n",
      " 0.8180  0.7179\n",
      " 0.8362  0.8655\n",
      "[torch.FloatTensor of size 2x2]\n",
      " \n",
      " 0.2021  0.0647\n",
      " 0.2605  0.4142\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# absolute value\n",
    "f = torch.FloatTensor([-1,-2,3])\n",
    "r0 = torch.abs(f)\n",
    "\n",
    "# addition\n",
    "x = torch.FloatTensor([-1, -2, 3])\n",
    "y = torch.FloatTensor([7, 4, -5])\n",
    "r1 = torch.add(x, 10) # add scalar 10 to x\n",
    "r2 = torch.add(x, 10, y) # sum of x, y, and scalar 10\n",
    "\n",
    "# clamp the value of a tensor\n",
    "v = torch.Tensor(2, 2).uniform_(0,1)\n",
    "r3 = torch.clamp(v, min=-0.5, max=0.5)\n",
    "\n",
    "# element-wise division\n",
    "r4 = torch.div(v, v+0.1)\n",
    "\n",
    "# element-wise multiplication\n",
    "r5 = torch.mul(v, v)\n",
    "\n",
    "print(r0,r1,r2,r3,r4,r5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcendental functions and other point-wise ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ".. autofunction:: abs\n",
    ".. autofunction:: acos           - arc cosine\n",
    ".. autofunction:: add\n",
    ".. autofunction:: addcdiv        - element wise: t1 + s * t2/t3\n",
    ".. autofunction:: addcmul        - element wise: t1 + s * t2 * t3\n",
    ".. autofunction:: asin           - arc sin\n",
    ".. autofunction:: atan\n",
    ".. autofunction:: atan2\n",
    ".. autofunction:: ceil           - ceiling\n",
    ".. autofunction:: clamp          - clamp elements into a range\n",
    ".. autofunction:: cos\n",
    ".. autofunction:: cosh\n",
    ".. autofunction:: div            - divide\n",
    ".. autofunction:: erf            - Gaussian error functiom\n",
    ".. autofunction:: erfinv         - Inverse\n",
    ".. autofunction:: exp\n",
    ".. autofunction:: expm1          - exponential of each element minus 1\n",
    ".. autofunction:: floor          \n",
    ".. autofunction:: fmod           - element wise remainder of division\n",
    ".. autofunction:: frac           - fraction part 3.4 -> 0.4\n",
    ".. autofunction:: lerp           - linear interpolation\n",
    ".. autofunction:: log            - natural log\n",
    ".. autofunction:: log1p          - y = log(1 + x)\n",
    ".. autofunction:: mul            - multiple\n",
    ".. autofunction:: neg \n",
    ".. autofunction:: pow\n",
    ".. autofunction:: reciprocal     - 1/x\n",
    ".. autofunction:: remainder      - remainder of division\n",
    ".. autofunction:: round\n",
    ".. autofunction:: rsqrt          - the reciprocal of the square-root \n",
    ".. autofunction:: sigmoid        - sigmode(x)\n",
    ".. autofunction:: sign\n",
    ".. autofunction:: sin\n",
    ".. autofunction:: sinh\n",
    ".. autofunction:: sqrt\n",
    ".. autofunction:: tan\n",
    ".. autofunction:: tanh\n",
    ".. autofunction:: trunc          - truncated integer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative sum, mean, product, etc.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T22:12:37.948854Z",
     "start_time": "2019-04-12T22:12:37.938436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  2  3\n",
      " 4  5  6\n",
      " 7  8  9\n",
      "[torch.FloatTensor of size 3x3]\n",
      " \n",
      " 5\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "  6\n",
      " 15\n",
      " 24\n",
      "[torch.FloatTensor of size 3]\n",
      " 45.0\n"
     ]
    }
   ],
   "source": [
    "# Cumulative sum\n",
    "v = torch.ones(9)\n",
    "r0 = torch.cumsum(v, dim=0).view(3,3)\n",
    "\n",
    "# Mean\n",
    "r1 = torch.mean(r0.view(9), dim=0)\n",
    "\n",
    "# Sum\n",
    "r2 = torch.sum(r0, dim=1)\n",
    "r3 = torch.sum(r0)\n",
    "\n",
    "print(r0,r1,r2,r3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other reduction operations\n",
    "\n",
    "```\n",
    ".. autofunction:: cumprod        - accumulate product of elements x1*x2*x3...\n",
    ".. autofunction:: cumsum\n",
    ".. autofunction:: dist           - L-p norm\n",
    ".. autofunction:: mean\n",
    ".. autofunction:: median\n",
    ".. autofunction:: mode\n",
    ".. autofunction:: norm           - L-p norm\n",
    ".. autofunction:: prod           - accumulate product\n",
    ".. autofunction:: std            - compute standard deviation\n",
    ".. autofunction:: sum\n",
    ".. autofunction:: var            - variance of all elem\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equality and range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T22:22:42.653507Z",
     "start_time": "2019-04-12T22:22:42.639716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v =  \n",
      " 0  1  2\n",
      " 3  4  5\n",
      " 6  7  8\n",
      "[torch.FloatTensor of size 3x3]\n",
      " \n",
      "\n",
      " r0 =  \n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.ByteTensor of size 3x3]\n",
      " \n",
      "\n",
      " r1 =  8.0 \n",
      "\n",
      " r2 =  (\n",
      " 2\n",
      " 5\n",
      " 8\n",
      "[torch.FloatTensor of size 3]\n",
      ", \n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 3]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "v = torch.arange(9).view(3,3)\n",
    "\n",
    "# element-wise comparison\n",
    "r0 = torch.eq(v, v)\n",
    "\n",
    "# max element\n",
    "r1 = torch.max(v) # max element in whole tensor\n",
    "r2 = torch.max(v, 1) # max element in dimension 1\n",
    "\n",
    "print(\"v = \", v, \"\\n\\n r0 = \", r0, \"\\n\\n r1 = \", r1, \"\\n\\n r2 = \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T22:27:21.442204Z",
     "start_time": "2019-04-12T22:27:21.431132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "-1.2034 -0.9490  0.3767\n",
      "-1.5232 -0.5664 -0.5357\n",
      "-0.6016  0.4215  1.7833\n",
      "[torch.FloatTensor of size 3x3]\n",
      ", \n",
      " 0  1  2\n",
      " 0  1  2\n",
      " 1  2  0\n",
      "[torch.LongTensor of size 3x3]\n",
      ") (\n",
      "-1.5232 -0.9490 -0.5357\n",
      "-1.2034 -0.6016  0.3767\n",
      " 1.7833 -0.5664  0.4215\n",
      "[torch.FloatTensor of size 3x3]\n",
      ", \n",
      " 1  0  1\n",
      " 0  2  0\n",
      " 2  1  2\n",
      "[torch.LongTensor of size 3x3]\n",
      ") (\n",
      "-1.5232\n",
      "-1.2034\n",
      "-0.9490\n",
      "-0.6016\n",
      "-0.5664\n",
      "-0.5357\n",
      " 0.3767\n",
      " 0.4215\n",
      " 1.7833\n",
      "[torch.FloatTensor of size 9]\n",
      ", \n",
      " 3\n",
      " 0\n",
      " 1\n",
      " 7\n",
      " 4\n",
      " 5\n",
      " 2\n",
      " 8\n",
      " 6\n",
      "[torch.LongTensor of size 9]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "v = torch.randn(9).view(3,3)\n",
    "r0 = torch.sort(v)\n",
    "r1 = torch.sort(v, 0)\n",
    "r2 = torch.sort(v.view(9))\n",
    "\n",
    "print(r0, r1, r2) # note that the second tuple of each output is the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-th and top k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T22:30:36.626247Z",
     "start_time": "2019-04-12T22:30:36.617342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-1.5232 -1.2034 -0.9490 -0.6016 -0.5664 -0.5357  0.3767  0.4215  1.7833\n",
      "[torch.FloatTensor of size 1x9]\n",
      " (\n",
      "-0.6016\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "v_sorted = torch.sort(v.view(1,9))[0]\n",
    "r0 = torch.kthvalue(v_sorted, 4)\n",
    "\n",
    "print(v_sorted, r0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T22:31:20.429370Z",
     "start_time": "2019-04-12T22:31:20.422709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      " 1.7833\n",
      "[torch.FloatTensor of size 1x1]\n",
      ", \n",
      " 8\n",
      "[torch.LongTensor of size 1x1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "r0 = torch.topk(v_sorted, 1)\n",
    "print(r0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other comparison ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ".. autofunction:: eq             - Compare elements\n",
    ".. autofunction:: equal          - True of 2 tensors are the same \n",
    ".. autofunction:: ge             - Element-wise greater or equal comparison\n",
    ".. autofunction:: gt\n",
    ".. autofunction:: kthvalue       - k-th element\n",
    ".. autofunction:: le\n",
    ".. autofunction:: lt\n",
    ".. autofunction:: max\n",
    ".. autofunction:: min\n",
    ".. autofunction:: ne\n",
    ".. autofunction:: sort\n",
    ".. autofunction:: topk           - top k\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix, vector multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dot product of Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T22:32:49.241962Z",
     "start_time": "2019-04-12T22:32:49.231057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot product of 2 tensors\n",
    "a = torch.Tensor([4, 2])\n",
    "b = torch.Tensor([3, 1])\n",
    "r = torch.dot(a, b)\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix-vector products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T22:37:58.610693Z",
     "start_time": "2019-04-12T22:37:58.603070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2.6792\n",
      "-2.3246\n",
      "[torch.FloatTensor of size 2]\n",
      " \n",
      "-0.3820\n",
      "-4.1244\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Matrix times vector\n",
    "A = torch.randn(2, 4)\n",
    "x = torch.randn(4)\n",
    "r0 = torch.mv(A, x)\n",
    "\n",
    "# Matrix + Matrix times vector\n",
    "B = torch.randn(2)\n",
    "A = torch.randn(2, 3)\n",
    "x = torch.randn(3)\n",
    "r1 = torch.addmv(B, A, x)\n",
    "\n",
    "print(r0, r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Matrix-Matrix products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T23:33:41.598280Z",
     "start_time": "2019-04-12T23:33:41.574281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-1.2783  1.6427 -1.4557  0.9254\n",
      "-0.4794  1.6348 -2.9228  0.0080\n",
      "[torch.FloatTensor of size 2x4]\n",
      " \n",
      " 0.5492 -1.1988 -0.2204  0.5866\n",
      " 4.1753 -3.2758  3.9218  0.6591\n",
      " 1.1895 -0.7514  0.6088  1.8811\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Matrix times Matrix\n",
    "m1 = torch.randn(2, 3)\n",
    "m2 = torch.randn(3, 4)\n",
    "r0 = torch.mm(m1, m2)\n",
    "\n",
    "# Matrix + Matrix times Matrix\n",
    "# Size 3x4\n",
    "M = torch.randn(3, 4)\n",
    "m1 = torch.randn(3, 2)\n",
    "m2 = torch.randn(2, 4)\n",
    "r1 = torch.addmm(M, m1, m2)\n",
    "\n",
    "print(r0, r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T23:35:35.428743Z",
     "start_time": "2019-04-12T23:35:35.415985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  1.2020  1.6921 -1.1332  1.0529  0.6079\n",
       " -0.6649 -0.4825  1.8081 -0.4529  1.4641\n",
       " -1.6707 -0.5038  1.3220 -0.2272  0.4810\n",
       "\n",
       "(1 ,.,.) = \n",
       "  1.0112  1.1443  0.7109 -0.7624  2.0415\n",
       "  0.4586  1.1151 -2.5277  1.5978  0.2435\n",
       "  0.7323 -0.5396  3.3860 -1.8553  1.8893\n",
       "\n",
       "(2 ,.,.) = \n",
       " -0.4275  1.2501 -1.2290 -0.9170  1.8273\n",
       " -0.6443  0.3324  0.6728  0.0685  0.5815\n",
       " -2.4623 -2.6342  2.0456 -2.7469 -1.0342\n",
       "\n",
       "(3 ,.,.) = \n",
       " -3.4735 -3.2363 -0.1630 -3.6588  1.4984\n",
       "  0.0211  0.3152  0.5639 -0.2571  0.0268\n",
       " -0.5573  1.4446  1.2297  0.8977  1.9769\n",
       "\n",
       "(4 ,.,.) = \n",
       " -1.7322  0.0131 -0.3421  0.3138  0.6157\n",
       " -2.0619 -1.4659  0.5456 -2.5309 -1.6549\n",
       "  3.8718  2.2077  0.3109  0.2547 -0.3231\n",
       "\n",
       "(5 ,.,.) = \n",
       "  1.4676 -4.6733 -4.1246 -0.7250 -1.4464\n",
       "  1.4983 -4.2356 -2.6123 -1.4424 -4.5579\n",
       " -9.2738  6.6039  1.2784 -4.7086  1.7607\n",
       "\n",
       "(6 ,.,.) = \n",
       " -0.0644  2.5195 -2.3923 -0.7669 -2.7215\n",
       "  3.6016 -3.5442  5.0215  1.8794  1.5366\n",
       " -2.4428  3.2052 -3.9410 -1.3501 -1.8186\n",
       "\n",
       "(7 ,.,.) = \n",
       " -0.7680 -0.0047  0.3483  0.1806  0.6439\n",
       "  1.2533  0.7235 -0.0824 -1.5236 -0.2689\n",
       "  0.8918  1.0555  4.0074 -0.1408  3.2855\n",
       "\n",
       "(8 ,.,.) = \n",
       "  4.0155 -3.0690 -1.3979 -2.9289 -1.7428\n",
       " -2.4415  0.9323  1.2397  1.9580  1.5453\n",
       "  0.5284 -0.0717  0.9828  0.9733  2.1436\n",
       "\n",
       "(9 ,.,.) = \n",
       "  0.1516 -0.7969  2.2147 -1.5551  1.1391\n",
       " -2.6087 -5.0341 -0.2261 -0.1458 -3.7458\n",
       " -4.7283 -2.9194 -0.4434  0.3603 -2.9934\n",
       "[torch.FloatTensor of size 10x3x5]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch Matrix x Matrix\n",
    "# Size 10x3x5\n",
    "batch1 = torch.randn(10, 3, 4)\n",
    "batch2 = torch.randn(10, 4, 5)\n",
    "r = torch.bmm(batch1, batch2)\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T23:36:05.627275Z",
     "start_time": "2019-04-12T23:36:05.617063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0  0  0  0\n",
       " 0  0  0  0  0\n",
       " 0  0  0  0  0\n",
       "[torch.FloatTensor of size 3x5]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.ones(3, 5)\n",
    "m2 = torch.ones(3, 5)\n",
    "v1 = torch.ones(3)\n",
    "\n",
    "# Cross product, 3x5\n",
    "r = torch.cross(m1, m2)\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagonal matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T23:36:30.831638Z",
     "start_time": "2019-04-12T23:36:30.824152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  0  0\n",
       " 0  1  0\n",
       " 0  0  1\n",
       "[torch.FloatTensor of size 3x3]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diagonal matrix, 3x3\n",
    "r = torch.diag(v1)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T23:36:41.739657Z",
     "start_time": "2019-04-12T23:36:41.731609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 2\n",
       " 1\n",
       " 0\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.histc(torch.FloatTensor([1, 2, 1]), bins=4, min=0, max=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T23:37:49.608630Z",
     "start_time": "2019-04-12T23:37:49.599442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-1.2034 -0.9490  0.3767\n",
      "-1.5232 -0.5664 -0.5357\n",
      " 1.7833 -0.6016  0.4215\n",
      "[torch.FloatTensor of size 3x3]\n",
      " \n",
      "-0.4758 -0.3752  0.1489\n",
      "-0.5802 -0.2157 -0.2040\n",
      " 0.6354 -0.2144  0.1502\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renormalize\n",
    "# Renormalize for L-1 at dim 0 with max of 1\n",
    "# 0.0000  0.3333  0.6667\n",
    "# 0.2500  0.3333  0.4167\n",
    "# 0.2857  0.3333  0.3810\n",
    "r = torch.renorm(v, 1, 0, 1)\n",
    "\n",
    "print(v, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Linear Algebra operations\n",
    "\n",
    "```\n",
    ".. autofunction:: cross           - cross product\n",
    ".. autofunction:: diag            - convert vector to diagonal matrix\n",
    ".. autofunction:: histc           - histogram\n",
    ".. autofunction:: renorm          - renormalize a tensor\n",
    ".. autofunction:: trace           - tr(M)\n",
    ".. autofunction:: tril            - lower triangle of 2-D matrix \n",
    ".. autofunction:: triu            - uppser triangle\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ".. autofunction:: is_tensor\n",
    ".. autofunction:: is_storage\n",
    ".. autofunction:: set_default_tensor_type\n",
    ".. autofunction:: numel\n",
    ".. autofunction:: set_printoptions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ".. autofunction:: save          - Saves an object to a disk file\n",
    ".. autofunction:: load          - Loads an object saved with torch.save() from a file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ".. autofunction:: get_num_threads - Gets the number of OpenMP threads used for parallelizing CPU operations\n",
    ".. autofunction:: set_num_threads\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ".. autofunction:: stft          - Short-time Fourier transform \n",
    ".. autofunction:: hann_window   - Hann window function\n",
    ".. autofunction:: hamming_window  - Hamming window function\n",
    ".. autofunction:: bartlett_window - Bartlett window function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLAS and LAPACK operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T21:23:45.839279Z",
     "start_time": "2019-04-12T21:23:45.825828Z"
    }
   },
   "source": [
    "```\n",
    ".. autofunction:: addbmm          - Batch add and mulitply matrices nxp + b×n×m X b×m×p -> bxnxp\n",
    ".. autofunction:: addmm           - Add and mulitply matrices nxp + n×m X m×p -> nxp\n",
    ".. autofunction:: addmv           - Add and matrix, vector multipy n + nxm X m -> n\n",
    ".. autofunction:: addr            - Outer product of vectors\n",
    ".. autofunction:: baddbmm         - Batch add and mulitply matrices\n",
    ".. autofunction:: bmm             - Batch mulitply matrices b×n×m X b×m×p -> b×n×p\n",
    ".. autofunction:: btrifact        - LU factorization\n",
    ".. autofunction:: btrifact_with_info\n",
    ".. autofunction:: btrisolve\n",
    ".. autofunction:: btriunpack\n",
    ".. autofunction:: dot             - Dot product of 2 tensors\n",
    ".. autofunction:: eig             - Eigenvalues and eigenvectors ofsquare matrix\n",
    ".. autofunction:: gels            - Solution for least square or p-norm(AX - B)\n",
    ".. autofunction:: geqrf\n",
    ".. autofunction:: ger             - Outer product of 2 vectors\n",
    ".. autofunction:: gesv            - Solve linear equations\n",
    ".. autofunction:: inverse         - Inverse of square matrix\n",
    ".. autofunction:: det             - Determinant of a 2D square Variable\n",
    ".. autofunction:: matmul          - Matrix product of tensors\n",
    ".. autofunction:: mm\t\t\t\t- Matrix multiplication\n",
    ".. autofunction:: mv              - Matrix vector product\n",
    ".. autofunction:: orgqr           - Orthogal matrix Q \n",
    ".. autofunction:: ormqr           - Multiplies matrix by the orthogonal Q matrix\n",
    ".. autofunction:: potrf           - Cholesky decomposition\n",
    ".. autofunction:: potri           - Inverse of a positive semidefinite matrix with Cholesky\n",
    ".. autofunction:: potrs           - Solve linear equation with positive semidefinite\n",
    ".. autofunction:: pstrf           - Cholesky decomposition of a positive semidefinite matrix\n",
    ".. autofunction:: qr              - QR decomposition\n",
    ".. autofunction:: svd             - SVD decomposition\n",
    ".. autofunction:: symeig          - Eigenvalues and eigenvectors\n",
    ".. autofunction:: trtrs           - Solves a system of equations with a triangular coefficient\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
